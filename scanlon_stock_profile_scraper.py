# -*- coding: utf-8 -*-
"""Scanlon_Stock_Profile_Scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_SwrUOf1GL7gxt1FuWFKIpMGi-oa2REJ
"""

#Import libraries for computation
import requests
import pandas as pd
from bs4 import BeautifulSoup
#Import libraries for file creation
import json
import csv
import sys


#Create User defined function for scraping stock profile data
def stock_profile_scraper(ticker):
  print(f'Now scraping Stock Profile data for {ticker}...')
  headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'}
  url = f'https://finance.yahoo.com/quote/{ticker}/profile'
  r = requests.get(url, headers=headers)
  #Scrape actual website
  soup = BeautifulSoup(r.text, 'html.parser')
  profile = { #start by scraping Stock Name, Address, and Key Executives
      'stock_name': soup.find('div', class_='D(ib) Mt(-5px) Maw(38%)--tab768 Maw(38%) Mend(10px) Ov(h) smartphone_Maw(85%) smartphone_Mend(0px)').find('div').text.strip(),
      'address': soup.find('div', class_='Mb(25px)').find('p', class_='D(ib) W(47.727%) Pend(40px)').get_text(separator='\n'),
      #For key executives, use a for loop to iterate through the list since it is a multi value attribute
      'key_executives': [name.text.strip() for name in soup.find('table', class_='W(100%)').find_all('td', class_='Ta(start)')],
  }
      #This line constructs a dictionary from the list of key executives and their positions. Use a step size of two since there is a executive iwth a coresponding position.
  profile['key_executives'] = {profile['key_executives'][i]: profile['key_executives'][i+1]
                              for i in range(0, len(profile['key_executives']), 2)}

  return profile

#select various stocks from the internet
tickers = ['TSLA', 'AMZN', 'AAPL', 'META', 'NFLX', 'GOOG', 'MSFT', 'SBUX', 'NKE', 'GME']
#Create empty list to append later
ticker_profiles = []
#Create for loop to iterate through list of stocks to scrape
for ticker in tickers:
  ticker_profiles.append(stock_profile_scraper(ticker))
#Write json file
with open('scanlon_stock_profile_scraper.json', 'w', encoding='utf-8') as f:
  json.dump(ticker_profiles, f, indent = 2)

#Write csv file
CSV_FILE_PATH = 'scanlon_stock_profile_scraper.csv'
with open(CSV_FILE_PATH, 'w', newline='', encoding='utf-8') as csvfile:
  fieldnames = ticker_profiles[0].keys()
  writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore')
  writer.writeheader()
  writer.writerows(ticker_profiles)
#Write excel file
EXCEL_FILE_PATH = 'scanlon_stock_profile_scraper.xlsx'
df = pd.DataFrame(ticker_profiles)
df.to_excel(EXCEL_FILE_PATH, index=False)

