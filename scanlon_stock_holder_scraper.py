# -*- coding: utf-8 -*-
"""Scanlon_Stock_Holder_Scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vuUC6VT5-0zF8HGnVOU_qMgqZUgn8Y7y
"""

#Import libraries for computation
import requests
import pandas as pd
from bs4 import BeautifulSoup
#Import libraries for file creation
import json
import csv
import sys


#Create User defined function for scraping stock profile data
def stock_holder_scraper(ticker):
  print(f'Now scraping Stock Holder data for {ticker}...')
  headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36'}
  url = f'https://finance.yahoo.com/quote/{ticker}/holders'
  r = requests.get(url, headers=headers)
  #Scrape actual website
  soup = BeautifulSoup(r.text, 'html.parser')
  holder_info = { #start by scraping Stock Name, Holders, Percents, Top Holders, Text Headers, Holder Data
      'stock_name': soup.find('div', class_='D(ib) Mt(-5px) Maw(38%)--tab768 Maw(38%) Mend(10px) Ov(h) smartphone_Maw(85%) smartphone_Mend(0px)').find('div').text.strip(),
      'holders': [holder.text.strip() for holder in soup.select('table.W\\(100\\%\\).M\\(0\\).BdB.Bdc\\(\$seperatorColor\\) td.Py\\(10px\\).Ta\\(start\\).Va\\(m\\)')],
      'percents': [percent.text.strip() for percent in soup.select('table[class="W(100%) M(0) BdB Bdc($seperatorColor)"] td[class="Py(10px) Va(m) Fw(600) W(15%)"]')],
      'top_holders': [top_holder.text.strip() for top_holder in soup.select('table[class="W(100%) BdB Bdc($seperatorColor)"] td[class="Ta(start) Pend(10px)"]')],
      'text_headers': [header.text.strip() for header in soup.select('table[class="W(100%) BdB Bdc($seperatorColor)"] th[class="Ta(end) Fw(400) Py(6px) Pstart(15px)"]')],
      'holder_data': [data.text.strip() for data in soup.select('table[class="W(100%) BdB Bdc($seperatorColor)"] td[class="Ta(end) Pstart(10px)"]')],
  }

  fixed_stock = {}
  # Copying the stock name
  fixed_stock['stock_name'] = holder_info['stock_name']

  # Combining holders and percents into a single dictionary
  holder_percent_pairs = {hldr: pct for hldr, pct in zip(holder_info['holders'], holder_info['percents'])}
  fixed_stock.update(holder_percent_pairs)

  # Splitting holder_data into chunks of 4 and combining with top_holders
  split_data = [holder_info["holder_data"][i:i+4] for i in range(0, len(holder_info["holder_data"]), 4)]
  for top_hldr, data in zip(holder_info.get('top_holders', []), split_data):
    holder_info = {header: value for header, value in zip(holder_info.get('text_headers', []), data)}
    fixed_stock[top_hldr] = holder_info




  return fixed_stock

#select various stocks from the internet
tickers = ['TSLA', 'AMZN', 'AAPL', 'META', 'NFLX', 'GOOG', 'MSFT', 'SBUX', 'NKE', 'GME']
#Create empty list to append later
ticker_holders = []
#Create for loop to iterate through list of stocks to scrape
for ticker in tickers:
  ticker_holders.append(stock_holder_scraper(ticker))
#Write json file
with open('scanlon_stock_holder_scraper.json', 'w', encoding='utf-8') as f:
  json.dump(ticker_holders, f, indent = 2)

#Write csv file
CSV_FILE_PATH = 'scanlon_stock_holder_scraper.csv'
with open(CSV_FILE_PATH, 'w', newline='', encoding='utf-8') as csvfile:
  fieldnames = ticker_holders[0].keys()
  writer = csv.DictWriter(csvfile, fieldnames=fieldnames, extrasaction='ignore')
  writer.writeheader()
  writer.writerows(ticker_holders)
#Write excel file
EXCEL_FILE_PATH = 'scanlon_stock_holder_scraper.xlsx'
df = pd.DataFrame(ticker_holders)
df.to_excel(EXCEL_FILE_PATH, index=False)

