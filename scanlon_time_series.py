# -*- coding: utf-8 -*-
"""Scanlon_Time_Series.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XrNPMrbQH64Jlv58dmzOSb--7VTqzaog
"""

import yfinance as yf
#Import the Libraries
import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
import datetime
plt.style.use("fivethirtyeight")

#Create Program

def time_series(ticker):
  # Create Ticker variables
  stock = yf.Ticker(ticker)
  #Set the time range
  stock_hist = stock.history(start=datetime.datetime(2010, 1, 1),end=datetime.datetime.today())
  stock_hist.head(20)

  #Create a new dataframe with only the Adj Close Column
  data = stock_hist.filter(["Close"])
  #Convert the dataframe to a numpy array
  dataset = data.values
  #Get the number of rows to train the model on
  training_data_len = math.ceil( len(dataset) *.8) #This is use to train 80% of the dataset

  #Scale the data
  scaler = MinMaxScaler(feature_range=(0,1))
  scaled_data = scaler.fit_transform(dataset)

  #Create the training model for the dataset
  #Create the scaled training dataset
  train_data = scaled_data[0:training_data_len , :]
  #Split the data into x_train & y_train
  x_train = []
  y_train = []

  for i in range(60, len(train_data)):
      x_train.append(train_data[i-60:i, 0])
      y_train.append(train_data[i, 0])

  x_train = np.array(x_train)

  # Reshape the data to a 3-dimensional shape
  x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))

  #Build the LSTM model
  model = Sequential()
  model.add(LSTM(50, return_sequences=True, input_shape= (x_train.shape[1], 1)))#50 means the no of input neurons
  model.add(LSTM(50, return_sequences= False))
  model.add(Dense(25))
  model.add(Dense(1))# Final output

  #Compile the model
  model.compile(optimizer="adam", loss="mean_squared_error")

  #Train the model
  y_train = np.array(y_train)

  model.fit(x_train, y_train, batch_size=1, epochs=5)

  #Create the testing data set
  #Create a new array containing scaled values from index 1543 to 2003
  test_data = scaled_data[training_data_len-60: , :]
  #Create the data sets x_test and y_test
  x_test = []
  y_test = dataset[training_data_len:, :]

  for i in range(60, len(test_data)):
      x_test.append(test_data[i-60:i, 0])
  #Convert the data to a numpy array
  x_test = np.array(x_test)#Reshape the data
  x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1 ))

  #Get the model predicted price values
  predictions = model.predict(x_test)
  predictions = scaler.inverse_transform(predictions)

  #Evaluate the model: Getting the root square error (RMSE)
  rmse = np.sqrt( np.mean( predictions - y_test )**2 )
  print(f'Root Mean Square Error: {rmse}')

  #Plot the data
  train = data[:training_data_len]
  valid = data[training_data_len:]
  valid["Predictions"] = predictions
  #Visualize the data
  plt.figure(figsize=(16,8))
  plt.title(f"{ticker}")
  plt.xlabel("Data", fontsize=18)
  plt.ylabel("Close Price USD ($)", fontsize=18)
  plt.plot(train["Close"])
  plt.plot(valid[["Close", "Predictions"]])
  plt.legend(["Train", "Val", "Predictions"], loc="lower right")
  print(plt.show())

ticker_list = ['SBUX', 'AAPL', 'GOOG']
for ticker in ticker_list:
  time_series(ticker)

